{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Train U-Net on the CAS Landslide Detection Dataset\n",
    "\n",
    "*Authors: Abdelouahed Drissi*"
   ],
   "id": "b24639b8faae326b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dataset",
   "id": "bd14e6d4dca9b41c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T11:01:57.442170Z",
     "start_time": "2024-11-26T11:01:36.061062Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from losses import dice_loss"
   ],
   "id": "f2aa39bf640a894a",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Function to read the image file",
   "id": "ef25cc1ce83653cc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T11:03:29.019137Z",
     "start_time": "2024-11-26T11:03:28.987833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_image_file(image_path, mask_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    mask = tf.io.read_file(mask_path)\n",
    "\n",
    "    image = tf.image.decode_png(image, channels=3)\n",
    "    mask = tf.image.decode_png(mask, channels=1)\n",
    "\n",
    "    return {\"image\": image, \"segmentation_mask\": mask}"
   ],
   "id": "7c131a4749b15ef0",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Loading the dataset",
   "id": "9bb40aa18495e789"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T11:04:51.818979Z",
     "start_time": "2024-11-26T11:03:29.670266Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dataset paths\n",
    "train_image_dir = \"./dataset/train/images\"\n",
    "train_mask_dir = \"./dataset/train/masks\"\n",
    "valid_image_dir = \"./dataset/validation/images\"\n",
    "valid_mask_dir = \"./dataset/validation/masks\"\n",
    "test_image_dir = \"./dataset/test/images\"\n",
    "test_mask_dir = \"./dataset/test/masks\"\n",
    "\n",
    "# Load datasets and match images with masks\n",
    "def load_data(image_dir, mask_dir):\n",
    "    image_names = sorted(os.listdir(image_dir))\n",
    "    mask_names = sorted(os.listdir(mask_dir))\n",
    "    pairs = []\n",
    "    for img_name in image_names:\n",
    "        mask_name = img_name.replace(\"image\", \"mask\")\n",
    "        if mask_name in mask_names:\n",
    "            pairs.append((os.path.join(image_dir, img_name), os.path.join(mask_dir, mask_name)))\n",
    "    data = [load_image_file(image_path, mask_path) for image_path, mask_path in pairs]\n",
    "    return data\n",
    "\n",
    "data_train = load_data(train_image_dir, train_mask_dir)\n",
    "data_valid = load_data(valid_image_dir, valid_mask_dir)\n",
    "data_test = load_data(test_image_dir, test_mask_dir)\n",
    "\n",
    "len(data_train), len(data_valid), len(data_test)"
   ],
   "id": "b28d7289a619ca09",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1385, 396, 199)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Normalization and Image Resizing",
   "id": "c8b308c9cfb32486"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T11:04:52.119870Z",
     "start_time": "2024-11-26T11:04:52.072568Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Normalize and preprocess images and masks\n",
    "image_size = 256\n",
    "mean = tf.constant([0.485, 0.456, 0.406])\n",
    "std = tf.constant([0.229, 0.224, 0.225])\n",
    "\n",
    "\n",
    "def normalize(input_image, input_mask):\n",
    "    input_image = tf.image.convert_image_dtype(input_image, tf.float32)\n",
    "    input_image = (input_image - mean) / tf.maximum(std, backend.epsilon())\n",
    "    input_mask = input_mask / 255\n",
    "    return input_image, input_mask\n",
    "\n",
    "\n",
    "def load_image(datapoint):\n",
    "    input_image = tf.image.resize(datapoint[\"image\"], (image_size, image_size))\n",
    "    input_mask = tf.image.resize(\n",
    "        datapoint[\"segmentation_mask\"],\n",
    "        (image_size, image_size),\n",
    "        method=\"bilinear\",\n",
    "    )\n",
    "    \n",
    "    input_image, input_mask = normalize(input_image, input_mask)\n",
    "    return ({\"pixel_values\": input_image}, input_mask)"
   ],
   "id": "b53a964d770faf2",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T11:05:16.447106Z",
     "start_time": "2024-11-26T11:04:52.129366Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_data = [load_image(datapoint) for datapoint in data_train]\n",
    "valid_data = [load_image(datapoint) for datapoint in data_valid]\n",
    "test_data = [load_image(datapoint) for datapoint in data_test]"
   ],
   "id": "5b82256e375ac5e9",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Build input pipeline",
   "id": "def54426f243329b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T11:05:18.149162Z",
     "start_time": "2024-11-26T11:05:16.957899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 4\n",
    "auto = tf.data.AUTOTUNE\n",
    "# Create dataset generators\n",
    "def generator(data):\n",
    "    for datapoint in data:\n",
    "        yield datapoint\n",
    "\n",
    "\n",
    "train_ds = tf.data.Dataset.from_generator(\n",
    "    lambda: generator(train_data),\n",
    "    output_types=({\"pixel_values\": tf.float32}, tf.int32),\n",
    "    output_shapes=({\"pixel_values\": (image_size, image_size, 3)}, (image_size, image_size,1))\n",
    ").cache().shuffle(batch_size * 10).batch(batch_size).repeat().prefetch(auto)\n",
    "\n",
    "valid_ds = tf.data.Dataset.from_generator(\n",
    "    lambda: generator(valid_data),\n",
    "    output_types=({\"pixel_values\": tf.float32}, tf.int32),\n",
    "    output_shapes=({\"pixel_values\": (image_size, image_size, 3)}, (image_size, image_size,1))\n",
    ").batch(batch_size).repeat().prefetch(auto)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_generator(\n",
    "    lambda: generator(test_data),\n",
    "    output_types=({\"pixel_values\": tf.float32}, tf.int32),\n",
    "    output_shapes=({\"pixel_values\": (image_size, image_size, 3)}, (image_size, image_size,1))\n",
    ").batch(batch_size).prefetch(auto)\n"
   ],
   "id": "7117751c7736ec15",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T11:05:18.260453Z",
     "start_time": "2024-11-26T11:05:18.232907Z"
    }
   },
   "cell_type": "code",
   "source": "print(train_ds.element_spec)\n",
   "id": "6e8bec264e8cd9ec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'pixel_values': TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name=None)}, TensorSpec(shape=(None, 256, 256, 1), dtype=tf.int32, name=None))\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model",
   "id": "914c45fc9d1bc4b9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T11:05:18.558545Z",
     "start_time": "2024-11-26T11:05:18.453422Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Image bands\n",
    "img_bands = 3\n",
    "\n",
    "# Loss function\n",
    "loss=dice_loss\n",
    "\n",
    "def unet(lr,filtersFirstLayer,input_size = (image_size,image_size,img_bands)):\n",
    "    inputs = Input(input_size, name=\"pixel_values\")\n",
    "    conv1 = Conv2D(filtersFirstLayer, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(inputs)\n",
    "    conv1 = Conv2D(filtersFirstLayer, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(filtersFirstLayer*2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(pool1)\n",
    "    conv2 = Conv2D(filtersFirstLayer*2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(filtersFirstLayer*4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(pool2)\n",
    "    conv3 = Conv2D(filtersFirstLayer*4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(filtersFirstLayer*8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(pool3)\n",
    "    conv4 = Conv2D(filtersFirstLayer*8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "    \n",
    "    conv5 = Conv2D(filtersFirstLayer*16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(pool4)\n",
    "    conv5 = Conv2D(filtersFirstLayer*16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(conv5)\n",
    "    \n",
    "    up6 = Conv2D(filtersFirstLayer*8, 2, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(UpSampling2D(size = (2,2))(conv5))\n",
    "    merge6 = concatenate([conv4,up6], axis = 3)\n",
    "    conv6 = Conv2D(filtersFirstLayer*8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(merge6)\n",
    "    conv6 = Conv2D(filtersFirstLayer*8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(conv6)\n",
    "    \n",
    "    up7 = Conv2D(filtersFirstLayer*4, 2, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = Conv2D(filtersFirstLayer*4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(merge7)\n",
    "    conv7 = Conv2D(filtersFirstLayer*4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(conv7)\n",
    "    \n",
    "    up8 = Conv2D(filtersFirstLayer*2, 2, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(filtersFirstLayer*2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(merge8)\n",
    "    conv8 = Conv2D(filtersFirstLayer*2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(conv8)\n",
    "    \n",
    "    up9 = Conv2D(filtersFirstLayer, 2, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    conv9 = Conv2D(filtersFirstLayer, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(merge9)\n",
    "    conv9 = Conv2D(filtersFirstLayer, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(conv9)\n",
    "    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(conv9)\n",
    "    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "    \n",
    "    model = Model(inputs=inputs,  outputs=conv10)\n",
    "    \n",
    "    model.compile(optimizer = Adam(learning_rate = lr), loss = loss)\n",
    "    print(\"Model input shape:\", model.input_shape)  # Expected: (None, image_size, image_size, 3)\n",
    "\n",
    "    return model"
   ],
   "id": "af48197dce70f308",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T11:05:18.606219Z",
     "start_time": "2024-11-26T11:05:18.576239Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training and evaluation loop parameters\n",
    "filters = [4, 8, 16, 32]\n",
    "learning_rates = [ 10e-3, 5e-4, 10e-4, 5e-5, 10e-5]\n",
    "batch_sizes = [4, 8, 16, 32]\n",
    "epochs = 5\n",
    "\n",
    "steps_per_epoch = len(train_data) // batch_size  # Number of batches per epoch\n"
   ],
   "id": "f62c6dcdb3cdba2e",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T18:21:21.249182Z",
     "start_time": "2024-11-25T18:06:37.558651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "for filter_count in filters:\n",
    "    for lr in learning_rates:\n",
    "        for batch in batch_sizes:\n",
    "            print(f\"Filters: {filter_count}, Learning Rate: {lr}, Batch Size: {batch}\")\n",
    "            model = unet(lr=lr, filtersFirstLayer=filter_count, input_size=(256, 256, 3))\n",
    "            early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)\n",
    "\n",
    "            # Save best model during training\n",
    "            checkpoint_path = f'./dataset/unet/weights/unet_filters_{filter_count}_batch_{batch}_lr_{lr}.keras'\n",
    "            model_checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, monitor='val_loss', save_best_only=True)\n",
    "\n",
    "\n",
    "            # Train the model\n",
    "            history = model.fit(\n",
    "                train_ds,\n",
    "                validation_data=valid_ds,\n",
    "                epochs=epochs,\n",
    "                steps_per_epoch=steps_per_epoch,\n",
    "                validation_steps=len(valid_data) // batch_size,\n",
    "                callbacks=[early_stop, model_checkpoint],\n",
    "                verbose=1\n",
    "            )"
   ],
   "id": "17d0f51c0d21fad5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filters: 4, Learning Rate: 0.0005, Batch Size: 4\n",
      "Model input shape: (None, 256, 256, 3)\n",
      "Epoch 1/5\n",
      "346/346 [==============================] - 266s 498ms/step - loss: 0.6955 - val_loss: 0.5705\n",
      "Epoch 2/5\n",
      "346/346 [==============================] - 170s 492ms/step - loss: 0.5181 - val_loss: 0.5185\n",
      "Epoch 3/5\n",
      "346/346 [==============================] - 157s 453ms/step - loss: 0.5070 - val_loss: 0.5048\n",
      "Epoch 4/5\n",
      "346/346 [==============================] - 140s 404ms/step - loss: 0.5037 - val_loss: 0.5034\n",
      "Epoch 5/5\n",
      "346/346 [==============================] - 142s 409ms/step - loss: 0.4918 - val_loss: 0.5073\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Testing and Metric Comparison Across Checkpoints",
   "id": "a01a8fff7773f5fa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T11:05:18.731919Z",
     "start_time": "2024-11-26T11:05:18.700415Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "id": "aa966267b8fd23c5",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T18:56:25.635921Z",
     "start_time": "2024-11-25T18:56:21.628548Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "results_dict = {\n",
    "    \"model\": [], \"batch_size\": [], \"learning_rate\": [], \"filters\": [],\n",
    "    \"precision\": [], \"recall\": [], \"f1_score\": [], \"iou_score\": []\n",
    "}\n",
    "# Metric functions (add these if not using a package like segmentation_models)\n",
    "def precision(y_true, y_pred):\n",
    "    y_pred = tf.round(y_pred)\n",
    "    true_positives = tf.reduce_sum(tf.round(y_true * y_pred))\n",
    "    predicted_positives = tf.reduce_sum(tf.round(y_pred))\n",
    "    return true_positives / (predicted_positives + tf.keras.backend.epsilon())\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    y_pred = tf.round(y_pred)\n",
    "    true_positives = tf.reduce_sum(tf.round(y_true * y_pred))\n",
    "    possible_positives = tf.reduce_sum(tf.round(y_true))\n",
    "    return true_positives / (tf.cast(possible_positives,tf.float32) + tf.keras.backend.epsilon())\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    return 2 * ((p * r) / (p + r + tf.keras.backend.epsilon()))\n",
    "\n",
    "def iou_score(y_true, y_pred): \n",
    "    y_pred = tf.round(y_pred)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    union = tf.reduce_sum(y_true + y_pred) - intersection\n",
    "    return intersection / (union + tf.keras.backend.epsilon())\n",
    "\n",
    "checkpoint_path = f'./dataset/unet/weights'\n",
    "for filename in os.listdir(checkpoint_path):\n",
    "    # Only load files with the proper model file extension\n",
    "    if filename.endswith(\".keras\"):     \n",
    "        # Define the model structure\n",
    "        filter_count = int(filename.split('_')[2])\n",
    "        lr = float(filename.split('_')[6].split('.keras')[0])\n",
    "        batch = int(filename.split('_')[4])\n",
    "        model = unet(lr=lr, filtersFirstLayer=filter_count, input_size=(256, 256, 3))\n",
    "        \n",
    "        # Load best model weights\n",
    "        model.load_weights(os.path.join(checkpoint_path, filename))\n",
    "        print(f\"Evaluating model with checkpoint: {filename}\")\n",
    "        \n",
    "        # Evaluate on test data\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        for sample in test_ds:\n",
    "            pred = model.predict(sample[0][\"pixel_values\"], verbose=0)\n",
    "            y_true.append(sample[1].numpy())\n",
    "            y_pred.append(pred)\n",
    "        \n",
    "        y_true = np.concatenate(y_true, axis=0)\n",
    "        y_pred = np.concatenate(y_pred, axis=0)\n",
    "        \n",
    "         # Ensure both y_true and y_pred have the same shape for metrics\n",
    "        if y_pred.shape[-1] == 1:\n",
    "            y_pred = np.squeeze(y_pred, axis=-1)  # Remove the last dimension if it's 1\n",
    "        if y_true.shape[-1] == 1:\n",
    "            y_true = np.squeeze(y_true, axis=-1)\n",
    "\n",
    "        # Compute and collect metrics\n",
    "        precision_val = precision(y_true, y_pred).numpy()\n",
    "        recall_val = recall(y_true, y_pred).numpy()\n",
    "        f1_val = f1_score(y_true, y_pred).numpy()\n",
    "        iou_val = iou_score(y_true, y_pred).numpy()\n",
    "        \n",
    "        results_dict[\"precision\"].append(precision_val)\n",
    "        results_dict[\"recall\"].append(recall_val)\n",
    "        results_dict[\"f1_score\"].append(f1_val)\n",
    "        results_dict[\"iou_score\"].append(iou_val)\n",
    "        \n",
    "        results_dict[\"model\"].append(\"U-Net\")\n",
    "        results_dict[\"batch_size\"].append(batch)\n",
    "        results_dict[\"learning_rate\"].append(lr)\n",
    "        results_dict[\"filters\"].append(filter_count)\n",
    "\n",
    "# Convert results_dict to DataFrame and save as CSV\n",
    "results_df = pd.DataFrame(results_dict)\n",
    "results_df.to_csv(\"dataset/unet/results/results_unet.csv\", index=False)\n",
    "\n",
    "print(\"Validation and metric calculation completed, results saved.\")"
   ],
   "id": "e227e049c276f459",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model input shape: (None, 256, 256, 3)\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Unable to open file (file signature not found)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[13], line 40\u001B[0m\n\u001B[0;32m     37\u001B[0m model \u001B[38;5;241m=\u001B[39m unet(lr\u001B[38;5;241m=\u001B[39mlr, filtersFirstLayer\u001B[38;5;241m=\u001B[39mfilter_count, input_size\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m256\u001B[39m, \u001B[38;5;241m256\u001B[39m, \u001B[38;5;241m3\u001B[39m))\n\u001B[0;32m     39\u001B[0m \u001B[38;5;66;03m# Load best model weights\u001B[39;00m\n\u001B[1;32m---> 40\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_weights\u001B[49m\u001B[43m(\u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcheckpoint_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     41\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEvaluating model with checkpoint: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfilename\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     43\u001B[0m \u001B[38;5;66;03m# Evaluate on test data\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\model\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\model\\lib\\site-packages\\h5py\\_hl\\files.py:561\u001B[0m, in \u001B[0;36mFile.__init__\u001B[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001B[0m\n\u001B[0;32m    552\u001B[0m     fapl \u001B[38;5;241m=\u001B[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001B[0;32m    553\u001B[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001B[0;32m    554\u001B[0m                      alignment_threshold\u001B[38;5;241m=\u001B[39malignment_threshold,\n\u001B[0;32m    555\u001B[0m                      alignment_interval\u001B[38;5;241m=\u001B[39malignment_interval,\n\u001B[0;32m    556\u001B[0m                      meta_block_size\u001B[38;5;241m=\u001B[39mmeta_block_size,\n\u001B[0;32m    557\u001B[0m                      \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    558\u001B[0m     fcpl \u001B[38;5;241m=\u001B[39m make_fcpl(track_order\u001B[38;5;241m=\u001B[39mtrack_order, fs_strategy\u001B[38;5;241m=\u001B[39mfs_strategy,\n\u001B[0;32m    559\u001B[0m                      fs_persist\u001B[38;5;241m=\u001B[39mfs_persist, fs_threshold\u001B[38;5;241m=\u001B[39mfs_threshold,\n\u001B[0;32m    560\u001B[0m                      fs_page_size\u001B[38;5;241m=\u001B[39mfs_page_size)\n\u001B[1;32m--> 561\u001B[0m     fid \u001B[38;5;241m=\u001B[39m make_fid(name, mode, userblock_size, fapl, fcpl, swmr\u001B[38;5;241m=\u001B[39mswmr)\n\u001B[0;32m    563\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(libver, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[0;32m    564\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_libver \u001B[38;5;241m=\u001B[39m libver\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\model\\lib\\site-packages\\h5py\\_hl\\files.py:235\u001B[0m, in \u001B[0;36mmake_fid\u001B[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001B[0m\n\u001B[0;32m    233\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m swmr \u001B[38;5;129;01mand\u001B[39;00m swmr_support:\n\u001B[0;32m    234\u001B[0m         flags \u001B[38;5;241m|\u001B[39m\u001B[38;5;241m=\u001B[39m h5f\u001B[38;5;241m.\u001B[39mACC_SWMR_READ\n\u001B[1;32m--> 235\u001B[0m     fid \u001B[38;5;241m=\u001B[39m \u001B[43mh5f\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mflags\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfapl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfapl\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    236\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mr+\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m    237\u001B[0m     fid \u001B[38;5;241m=\u001B[39m h5f\u001B[38;5;241m.\u001B[39mopen(name, h5f\u001B[38;5;241m.\u001B[39mACC_RDWR, fapl\u001B[38;5;241m=\u001B[39mfapl)\n",
      "File \u001B[1;32mh5py\\\\_objects.pyx:54\u001B[0m, in \u001B[0;36mh5py._objects.with_phil.wrapper\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mh5py\\\\_objects.pyx:55\u001B[0m, in \u001B[0;36mh5py._objects.with_phil.wrapper\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mh5py\\\\h5f.pyx:102\u001B[0m, in \u001B[0;36mh5py.h5f.open\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mOSError\u001B[0m: Unable to open file (file signature not found)"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Sample Predictions (Ground Truth vs. Predicted Masks for model with the best F1_score)",
   "id": "a2f970a1f718edea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T13:44:15.998074800Z",
     "start_time": "2024-11-26T11:05:18.818707Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_sample_predictions(test_ds, model, num_samples=3):\n",
    "    plt.figure(figsize=(15, num_samples * 5))\n",
    "    \n",
    "    for i, sample in enumerate(test_ds.take(num_samples)):\n",
    "        input_image = sample[0][\"pixel_values\"]  # Taking first image in batch\n",
    "        ground_truth_mask = sample[1]\n",
    "        \n",
    "        # Predict\n",
    "        pred_mask = model.predict(input_image, verbose=0)\n",
    "        \n",
    "        image = input_image.numpy()[0]\n",
    "        image = (image - image.min()) / (image.max() - image.min())  # Normalize to [0, 1]\n",
    "\n",
    "        # Plot input, ground truth, and prediction\n",
    "        plt.subplot(num_samples, 3, i*3 + 1)\n",
    "        plt.imshow(image)\n",
    "        plt.title(\"Input Image\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(num_samples, 3, i*3 + 2)\n",
    "        plt.imshow(ground_truth_mask.numpy()[0], cmap='gray')\n",
    "        plt.title(\"Ground Truth Mask\")\n",
    "        plt.axis(\"off\")\n",
    "        \n",
    "        plt.subplot(num_samples, 3, i*3 + 3)\n",
    "        plt.imshow(pred_mask[0], cmap='gray')\n",
    "        plt.title(\"Predicted Mask\")\n",
    "        plt.axis(\"off\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"dataset/unet/results/sample_predictions.png\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Find the model with the best f1_score\n",
    "df = pd.read_csv(\"dataset/unet/results/results_unet.csv\")\n",
    "maxIndex = df[\"iou_score\"].idxmax()\n",
    "filter_count = df[\"filters\"][maxIndex]\n",
    "lr = df[\"learning_rate\"][maxIndex]\n",
    "batch_size = df[\"batch_size\"][maxIndex]\n",
    "\n",
    "filename = f'./dataset/unet/weights/unet_filters_{filter_count}_batch_{batch_size}_lr_{lr}.keras'\n",
    "print(f\"Plot sample from file: {filename}\")\n",
    "# Load best model weights\n",
    "model = unet(lr=lr, filtersFirstLayer=filter_count, input_size=(256, 256, 3))\n",
    "model.load_weights(filename)\n",
    "\n",
    "\n",
    "plot_sample_predictions(test_ds, model)\n"
   ],
   "id": "f93ee9b3acfd8200",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot sample from file: ./dataset/unet/weights/unet_filters_4_batch_4_lr_0.0005.keras\n",
      "Model input shape: (None, 256, 256, 3)\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T15:29:41.116561Z",
     "start_time": "2024-11-24T15:29:41.044765Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_metrics_comparison(results_df):\n",
    "    metrics = [\"precision\", \"recall\", \"f1_score\", \"iou_score\"]\n",
    "    plt.figure(figsize=(14, 8))\n",
    "\n",
    "    for i, metric in enumerate(metrics):\n",
    "        plt.subplot(2, 2, i+1)\n",
    "        sorted_df = results_df.sort_values(by='batch_size')\n",
    "        plt.bar(sorted_df.index, sorted_df[metric], color='skyblue')\n",
    "        plt.xticks(sorted_df.index, sorted_df['batch_size'], rotation=90)\n",
    "        plt.title(f\"{metric.capitalize()} Across Configurations\")\n",
    "        plt.xlabel(\"Configurations (Batch Size)\")\n",
    "        plt.ylabel(metric.capitalize())\n",
    "        plt.grid(axis='y')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"data/model/unet/results/metrics_comparison.png\")\n",
    "    plt.show()\n",
    "\n",
    "# After collecting results\n",
    "plot_metrics_comparison(results_df)"
   ],
   "id": "29ca15239c6573ea",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[16], line 20\u001B[0m\n\u001B[0;32m     17\u001B[0m     plt\u001B[38;5;241m.\u001B[39mshow()\n\u001B[0;32m     19\u001B[0m \u001B[38;5;66;03m# After collecting results\u001B[39;00m\n\u001B[1;32m---> 20\u001B[0m plot_metrics_comparison(\u001B[43mresults_df\u001B[49m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'results_df' is not defined"
     ]
    }
   ],
   "execution_count": 16
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
