{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b24639b8faae326b",
   "metadata": {},
   "source": [
    "# Train U-Net on the CAS Landslide Detection Dataset\n",
    "\n",
    "*Authors: Abdelouahed Drissi*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd14e6d4dca9b41c",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2aa39bf640a894a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T11:01:57.442170Z",
     "start_time": "2024-11-26T11:01:36.061062Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 11:36:57.524648: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-22 11:36:57.592656: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from losses import weighted_bce\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef25cc1ce83653cc",
   "metadata": {},
   "source": [
    "### Function to read the image file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c131a4749b15ef0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T11:03:29.019137Z",
     "start_time": "2024-11-26T11:03:28.987833Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_image_file(image_path, mask_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    mask = tf.io.read_file(mask_path)\n",
    "\n",
    "    image = tf.image.decode_png(image, channels=3)\n",
    "    mask = tf.image.decode_png(mask, channels=1)\n",
    "\n",
    "    return {\"image\": image, \"segmentation_mask\": mask}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2313d485",
   "metadata": {},
   "source": [
    "### Costum Functions for data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ef65ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define number of augmented copies per original image\n",
    "AUGMENTATION_FACTOR = 2\n",
    "\n",
    "# Define augmentation functions\n",
    "def random_flip(image, mask):\n",
    "    \"\"\"Random horizontal and vertical flips\"\"\"\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        image = tf.image.flip_left_right(image)\n",
    "        mask = tf.image.flip_left_right(mask)\n",
    "    \n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        image = tf.image.flip_up_down(image)\n",
    "        mask = tf.image.flip_up_down(mask)\n",
    "    \n",
    "    return image, mask\n",
    "\n",
    "def random_rotate(image, mask):\n",
    "    \"\"\"Random rotation (0째, 90째, 180째, 270째)\"\"\"\n",
    "    k = tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32)\n",
    "    image = tf.image.rot90(image, k=k)\n",
    "    mask = tf.image.rot90(mask, k=k)\n",
    "    return image, mask\n",
    "\n",
    "def random_brightness(image, mask):\n",
    "    \"\"\"Random brightness adjustment\"\"\"\n",
    "    image = tf.image.random_brightness(image, max_delta=2.5)\n",
    "    return image, mask\n",
    "\n",
    "def random_contrast(image, mask):\n",
    "    \"\"\"Random contrast adjustment\"\"\"\n",
    "    image = tf.image.random_contrast(image, lower=0.2, upper=1.4)\n",
    "    return image, mask\n",
    "\n",
    "def augment_data(image, mask):\n",
    "    \"\"\"Apply all augmentations sequentially\"\"\"\n",
    "    image, mask = random_flip(image, mask)\n",
    "    image, mask = random_rotate(image, mask)\n",
    "    image, mask = random_brightness(image, mask)\n",
    "    image, mask = random_contrast(image, mask)\n",
    "    return image, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb40aa18495e789",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28d7289a619ca09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T11:04:51.818979Z",
     "start_time": "2024-11-26T11:03:29.670266Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dataset paths\n",
    "train_image_dir = \"./dataset/train/images\"\n",
    "train_mask_dir = \"./dataset/train/masks\"\n",
    "valid_image_dir = \"./dataset/validation/images\"\n",
    "valid_mask_dir = \"./dataset/validation/masks\"\n",
    "test_image_dir = \"./dataset/test/images\"\n",
    "test_mask_dir = \"./dataset/test/masks\"\n",
    "\n",
    "# Load datasets and match images with masks\n",
    "def load_data(image_dir, mask_dir):\n",
    "    image_names = sorted(os.listdir(image_dir))\n",
    "    mask_names = sorted(os.listdir(mask_dir))\n",
    "    pairs = []\n",
    "    for img_name in image_names:\n",
    "        mask_name = img_name.replace(\"image\", \"mask\")\n",
    "        if mask_name in mask_names:\n",
    "            pairs.append((os.path.join(image_dir, img_name), os.path.join(mask_dir, mask_name)))\n",
    "    data = [load_image_file(image_path, mask_path) for image_path, mask_path in pairs]\n",
    "    return data\n",
    " \n",
    "# Modified load_data function with augmentation\n",
    "def load_data_with_augmentation(image_dir, mask_dir):    \n",
    "    # Load original data\n",
    "    original_data = load_data(image_dir, mask_dir)\n",
    "\n",
    "    # Generate augmented data\n",
    "    augmented_data = []\n",
    "    for datapoint in original_data:\n",
    "        for _ in range(AUGMENTATION_FACTOR):\n",
    "            # Apply random augmentations\n",
    "            image = datapoint[\"image\"]\n",
    "            mask = datapoint[\"segmentation_mask\"]\n",
    "            \n",
    "            # Apply augmentation chain\n",
    "            aug_image, aug_mask = augment_data(image, mask)\n",
    "            augmented_data.append({\"image\": aug_image, \"segmentation_mask\": aug_mask})\n",
    "    \n",
    "    # Combine original + augmented data\n",
    "    return original_data + augmented_data\n",
    "\n",
    "# Create augmented datasets\n",
    "data_train = load_data_with_augmentation(train_image_dir, train_mask_dir)\n",
    "data_valid = load_data(valid_image_dir, valid_mask_dir)\n",
    "data_test = load_data(test_image_dir, test_mask_dir)\n",
    "\n",
    "len(data_train), len(data_valid), len(data_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdccf0a",
   "metadata": {},
   "source": [
    "### Mean an STD calculation\n",
    "#### Run this cell if you want to recalculate Mean and STD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c89983",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dataset_statistics(image_dir):\n",
    "    \"\"\"\n",
    "    Compute mean and standard deviation for each band in the dataset.\n",
    "    \"\"\"\n",
    "    image_paths = sorted([os.path.join(image_dir, f) for f in os.listdir(image_dir)])\n",
    "    sum_ = np.zeros(3)\n",
    "    sum_sq = np.zeros(3)\n",
    "    count = 0\n",
    "\n",
    "    for img_path in image_paths:\n",
    "        \n",
    "        image = tf.io.read_file(img_path)\n",
    "        image = tf.image.decode_png(image, channels=3)\n",
    "        \n",
    "        # Resize to target size (if needed)\n",
    "        image = tf.image.resize(image, (image_size, image_size), method=\"bilinear\")\n",
    "        \n",
    "        sum_ += np.mean(image, axis=(0, 1))\n",
    "        sum_sq += np.mean(image**2, axis=(0, 1))\n",
    "        count += 1\n",
    "\n",
    "    mean = sum_ / count\n",
    "    std = np.sqrt((sum_sq / count) - (mean ** 2))\n",
    "    return mean, std\n",
    "\n",
    "# Compute mean/std for the training data\n",
    "mean, std = compute_dataset_statistics(train_image_dir)\n",
    "\n",
    "# Convert to tensors for TensorFlow operations\n",
    "mean = tf.constant(mean, dtype=tf.float32)\n",
    "std = tf.constant(std, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b308c9cfb32486",
   "metadata": {},
   "source": [
    "### Normalization and Image Resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53a964d770faf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T11:04:52.119870Z",
     "start_time": "2024-11-26T11:04:52.072568Z"
    }
   },
   "outputs": [],
   "source": [
    "# Normalize and preprocess images and masks\n",
    "image_size = 256\n",
    "# Original statistics from the CAS Dataset\n",
    "mean = tf.constant([0.485, 0.456, 0.406])\n",
    "std = tf.constant([0.229, 0.224, 0.225])\n",
    "\n",
    "def normalize(input_image, input_mask):\n",
    "    input_image = tf.image.convert_image_dtype(input_image, tf.float32)\n",
    "    #input_image = (input_image - mean[None, None, :]) / tf.maximum(std[ None, None, :], tf.keras.backend.epsilon()) # Uncomment this line if you want to normalize to [-1 1]\n",
    "    input_image = (input_image ) / 255.0    # Normalize to [0 1] range\n",
    "    input_mask = input_mask / 255.0         # Normalize to [0 1] range\n",
    "   \n",
    "    return input_image, input_mask\n",
    "\n",
    "\n",
    "def load_image(datapoint):\n",
    "    input_image = tf.image.resize(datapoint[\"image\"], (image_size, image_size))\n",
    "    input_mask = tf.image.resize(\n",
    "        datapoint[\"segmentation_mask\"],\n",
    "        (image_size, image_size),\n",
    "        method=\"bilinear\",\n",
    "    )\n",
    "    \n",
    "    input_image, input_mask = normalize(input_image, input_mask)\n",
    "    return ({\"pixel_values\": input_image}, input_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b82256e375ac5e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T11:05:16.447106Z",
     "start_time": "2024-11-26T11:04:52.129366Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = [load_image(datapoint) for datapoint in data_train]\n",
    "valid_data = [load_image(datapoint) for datapoint in data_valid]\n",
    "test_data = [load_image(datapoint) for datapoint in data_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def54426f243329b",
   "metadata": {},
   "source": [
    "### Build input pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7117751c7736ec15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T11:05:18.149162Z",
     "start_time": "2024-11-26T11:05:16.957899Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "auto = tf.data.AUTOTUNE\n",
    "# Create dataset generators\n",
    "def generator(data):\n",
    "    for datapoint in data:\n",
    "        yield datapoint\n",
    "\n",
    "\n",
    "train_ds = tf.data.Dataset.from_generator(\n",
    "    lambda: generator(train_data),\n",
    "    output_types=({\"pixel_values\": tf.float32}, tf.float32),\n",
    "    output_shapes=({\"pixel_values\": (image_size, image_size, 3)}, (image_size, image_size,1))\n",
    ").cache().shuffle(batch_size * 10).batch(batch_size).repeat().prefetch(auto)\n",
    "\n",
    "valid_ds = tf.data.Dataset.from_generator(\n",
    "    lambda: generator(valid_data),\n",
    "    output_types=({\"pixel_values\": tf.float32}, tf.float32),\n",
    "    output_shapes=({\"pixel_values\": (image_size, image_size, 3)}, (image_size, image_size,1))\n",
    ").batch(batch_size).repeat().prefetch(auto)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_generator(\n",
    "    lambda: generator(test_data),\n",
    "    output_types=({\"pixel_values\": tf.float32}, tf.float32),\n",
    "    output_shapes=({\"pixel_values\": (image_size, image_size, 3)}, (image_size, image_size,1))\n",
    ").batch(batch_size).prefetch(auto)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d91b0e",
   "metadata": {},
   "source": [
    "### Performance Metrics Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d042b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(y_true, y_pred):\n",
    "    y_pred = tf.round(y_pred)\n",
    "    true_positives = tf.reduce_sum(tf.round(y_true * y_pred))\n",
    "    possible_positives = tf.reduce_sum(tf.round(y_true))\n",
    "    return true_positives / (tf.cast(possible_positives,tf.float32) + tf.keras.backend.epsilon())\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    y_pred = tf.round(y_pred)\n",
    "    true_positives = tf.reduce_sum(tf.round(y_true * y_pred))\n",
    "    predicted_positives = tf.reduce_sum(tf.round(y_pred))\n",
    "    return true_positives / (predicted_positives + tf.keras.backend.epsilon())\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    return 2 * ((p * r) / (p + r + tf.keras.backend.epsilon()))\n",
    "\n",
    "def f2_score(y_true, y_pred):\n",
    "    \"\"\"F2-score prioritizing recall over precision\"\"\"\n",
    "    \n",
    "    # Precision and recall with stability\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    \n",
    "    # F-beta calculation (beta=2)\n",
    "    beta_sq = 4\n",
    "    return (1 + beta_sq) * (p * r) / (beta_sq * p + r + tf.keras.backend.epsilon())\n",
    "\n",
    "def iou_score(y_true, y_pred): \n",
    "    y_pred = tf.round(y_pred)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    union = tf.reduce_sum(y_true + y_pred) - intersection\n",
    "    return intersection / (union + tf.keras.backend.epsilon())\n",
    "\n",
    "def miss_rate(y_true, y_pred):\n",
    "    \"\"\"Percentage of undetected landslides\"\"\"\n",
    "    y_pred = tf.round(y_pred)\n",
    "    false_negatives = tf.reduce_sum(y_true * (1 - y_pred))\n",
    "    possible_positives = tf.reduce_sum(y_true)\n",
    "    \n",
    "    return tf.where(\n",
    "        possible_positives > 0,\n",
    "        false_negatives / (possible_positives + tf.keras.backend.epsilon()),\n",
    "        0.0  # No landslides to miss\n",
    "    )\n",
    "\n",
    "def false_positive_rate(y_true, y_pred):\n",
    "    \"\"\"FP rate with edge case handling\"\"\"\n",
    "    y_pred = tf.round(y_pred)\n",
    "    \n",
    "    false_positives = tf.reduce_sum((1 - y_true) * y_pred)\n",
    "    true_negatives = tf.reduce_sum((1 - y_true) * (1 - y_pred))\n",
    "    \n",
    "    return tf.where(\n",
    "        (false_positives + true_negatives) > 0,\n",
    "        false_positives / (false_positives + true_negatives + tf.keras.backend.epsilon()),\n",
    "        0.0  # No negative samples\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914c45fc9d1bc4b9",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af48197dce70f308",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T11:05:18.558545Z",
     "start_time": "2024-11-26T11:05:18.453422Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout, BatchNormalization\n",
    "\n",
    "# Image bands\n",
    "img_bands = 3\n",
    "# Loss function\n",
    "loss=weighted_bce\n",
    "\n",
    "def unet(lr,filtersFirstLayer,input_size = (image_size,image_size,img_bands)):\n",
    "    inputs = Input(input_size, name=\"pixel_values\")\n",
    "    conv1 = Conv2D(filtersFirstLayer, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(inputs)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Conv2D(filtersFirstLayer, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    #pool1 = Dropout(Dropout_Rate)(pool1)\n",
    "\n",
    "    conv2 = Conv2D(filtersFirstLayer*2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(pool1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Conv2D(filtersFirstLayer*2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    #pool2 = Dropout(Dropout_Rate)(pool2)\n",
    "\n",
    "    conv3 = Conv2D(filtersFirstLayer*4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(pool2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Conv2D(filtersFirstLayer*4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    #pool3 = Dropout(Dropout_Rate)(pool3)\n",
    "\n",
    "    conv4 = Conv2D(filtersFirstLayer*8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(pool3)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Conv2D(filtersFirstLayer*8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "    #pool4 = Dropout(Dropout_Rate)(pool4)\n",
    "\n",
    "    conv5 = Conv2D(filtersFirstLayer*16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(pool4)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Conv2D(filtersFirstLayer*16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(conv5)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    \n",
    "    up6 = Conv2D(filtersFirstLayer*8, 2, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(UpSampling2D(size = (2,2))(conv5))\n",
    "    merge6 = concatenate([conv4,up6], axis = 3)\n",
    "    conv6 = Conv2D(filtersFirstLayer*8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(merge6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Conv2D(filtersFirstLayer*8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    \n",
    "    up7 = Conv2D(filtersFirstLayer*4, 2, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = Conv2D(filtersFirstLayer*4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(merge7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    conv7 = Conv2D(filtersFirstLayer*4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(conv7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    \n",
    "    up8 = Conv2D(filtersFirstLayer*2, 2, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(filtersFirstLayer*2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(merge8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "    conv8 = Conv2D(filtersFirstLayer*2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(conv8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "    \n",
    "    up9 = Conv2D(filtersFirstLayer, 2, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    conv9 = Conv2D(filtersFirstLayer, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(merge9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "    conv9 = Conv2D(filtersFirstLayer, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(conv9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(conv9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "    \n",
    "    model = Model(inputs=inputs,  outputs=conv10)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer = Adam(learning_rate = lr)\n",
    "        , loss = loss\n",
    "        , metrics=[\n",
    "                    recall,\n",
    "                    f2_score,\n",
    "                    miss_rate,\n",
    "                    false_positive_rate,\n",
    "                    tf.keras.metrics.Precision(name='precision')  # Monitor but don't optimize\n",
    "                ]\n",
    "    )\n",
    "    print(\"Model input shape:\", model.input_shape)  # Expected: (None, image_size, image_size, 3)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62c6dcdb3cdba2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T11:05:18.606219Z",
     "start_time": "2024-11-26T11:05:18.576239Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "# Training and evaluation loop parameters\n",
    "filters = [4,8,16,32]\n",
    "learning_rates = [10e-3, 5e-4, 10e-4, 5e-5, 10e-5]\n",
    "batch_sizes = [4,8,16,32]\n",
    "epochs = 100\n",
    "\n",
    "steps_per_epoch = len(train_data) // batch_size  # Number of batches per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d0f51c0d21fad5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T18:21:21.249182Z",
     "start_time": "2024-11-25T18:06:37.558651Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "for filter_count in filters:\n",
    "    for lr in learning_rates:\n",
    "        for batch in batch_sizes:\n",
    "            # Clean up memory\n",
    "            model = None\n",
    "            tf.keras.backend.clear_session() \n",
    "            gc.collect() \n",
    "            print(f\"Filters: {filter_count}, Learning Rate: {lr}, Batch Size: {batch}\")\n",
    "            model = unet(lr=lr, filtersFirstLayer=filter_count, input_size=(image_size, image_size, 3))\n",
    "            early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)\n",
    "\n",
    "            # Save best model during training\n",
    "            checkpoint_path = f'./dataset/unet/weights/unet_filters_{filter_count}_batch_{batch}_lr_{lr}.keras'\n",
    "            model_checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, monitor='val_loss', save_best_only=True)\n",
    "\n",
    "            # Train the model\n",
    "            history = model.fit(\n",
    "                train_ds,\n",
    "                validation_data=valid_ds,\n",
    "                epochs=epochs,\n",
    "                steps_per_epoch=steps_per_epoch,\n",
    "                validation_steps=len(valid_data) // batch_size,\n",
    "                callbacks=[early_stop, model_checkpoint],\n",
    "                verbose=1\n",
    "            )\n",
    "\n",
    "            # Final evaluation\n",
    "            results = model.evaluate(test_ds)\n",
    "            print(f\"Test Recall: {results[1]:.2%}, Miss Rate: {results[3]:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01a8fff7773f5fa",
   "metadata": {},
   "source": [
    "### Testing and Metric Comparison Across Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e227e049c276f459",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T18:56:25.635921Z",
     "start_time": "2024-11-25T18:56:21.628548Z"
    }
   },
   "outputs": [],
   "source": [
    "results_dict = {\n",
    "    \"model\": [], \"batch_size\": [], \"learning_rate\": [], \"filters\": [],\n",
    "    \"precision\": [], \"recall\": [], \"f1_score\": [], \"iou_score\": [],\n",
    "    \"f2_score\": [],\"miss_rate\": [],\"false_positive_rate\": [],\n",
    "\n",
    "}\n",
    "\n",
    "checkpoint_path = f'./dataset/unet/weights/'\n",
    "for filename in os.listdir(checkpoint_path):\n",
    "    # Only load files with the proper model file extension\n",
    "    if filename.endswith(\".keras\"): \n",
    "        # Clean up memory\n",
    "        model = None\n",
    "        tf.keras.backend.clear_session() \n",
    "        gc.collect()\n",
    "             \n",
    "        # Define the model structure\n",
    "        filter_count = int(filename.split('_')[2])\n",
    "        lr = float(filename.split('_')[6].split('.keras')[0])\n",
    "        batch = int(filename.split('_')[4])\n",
    "        model = unet(lr=lr, filtersFirstLayer=filter_count, input_size=(image_size, image_size, 3))\n",
    "        \n",
    "        # Load best model weights\n",
    "        model.load_weights(os.path.join(checkpoint_path, filename))\n",
    "        print(f\"Evaluating model with checkpoint: {filename}\")\n",
    "        \n",
    "        # Evaluate on test data\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        for sample in test_ds:\n",
    "            pred = model.predict(sample[0][\"pixel_values\"], verbose=0)\n",
    "            y_true.append(sample[1].numpy())\n",
    "            y_pred.append(pred)\n",
    "        \n",
    "        y_true = np.concatenate(y_true, axis=0)\n",
    "        y_pred = np.concatenate(y_pred, axis=0)\n",
    "        \n",
    "         # Ensure both y_true and y_pred have the same shape for metrics\n",
    "        if y_pred.shape[-1] == 1:\n",
    "            y_pred = np.squeeze(y_pred, axis=-1)  # Remove the last dimension if it's 1\n",
    "        if y_true.shape[-1] == 1:\n",
    "            y_true = np.squeeze(y_true, axis=-1)\n",
    "\n",
    "        # Compute and collect metrics\n",
    "        precision_val = precision(y_true, y_pred).numpy()\n",
    "        recall_val = recall(y_true, y_pred).numpy()\n",
    "        f1_val = f1_score(y_true, y_pred).numpy()\n",
    "        iou_val = iou_score(y_true, y_pred).numpy()\n",
    "        \n",
    "        f2_val = f2_score(y_true, y_pred).numpy()\n",
    "        miss_rate_val = miss_rate(y_true, y_pred).numpy()\n",
    "        fpr_val = false_positive_rate(y_true, y_pred).numpy()\n",
    "\n",
    "        results_dict[\"precision\"].append(precision_val)\n",
    "        results_dict[\"recall\"].append(recall_val)\n",
    "        results_dict[\"f1_score\"].append(f1_val)\n",
    "        results_dict[\"iou_score\"].append(iou_val)\n",
    "        results_dict[\"f2_score\"].append(f2_val)\n",
    "        results_dict[\"miss_rate\"].append(miss_rate_val)\n",
    "        results_dict[\"false_positive_rate\"].append(fpr_val)\n",
    "\n",
    "        results_dict[\"model\"].append(\"U-Net\")\n",
    "        results_dict[\"batch_size\"].append(batch)\n",
    "        results_dict[\"learning_rate\"].append(lr)\n",
    "        results_dict[\"filters\"].append(filter_count)\n",
    "\n",
    "# Convert results_dict to DataFrame and save as CSV\n",
    "results_df = pd.DataFrame(results_dict)\n",
    "results_df.to_csv(\"dataset/unet/results/results_unet.csv\", index=False)\n",
    "\n",
    "print(\"Validation and metric calculation completed, results saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f970a1f718edea",
   "metadata": {},
   "source": [
    "### Sample Predictions (Ground Truth vs. Predicted Masks for model with the best F2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93ee9b3acfd8200",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T13:44:15.998074800Z",
     "start_time": "2024-11-26T11:05:18.818707Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_sample_predictions(test_ds, model, num_samples=3):\n",
    "    plt.figure(figsize=(15, num_samples * 5))\n",
    "    \n",
    "    for i, sample in enumerate(test_ds.take(num_samples)):\n",
    "        input_image = sample[0][\"pixel_values\"]  # Taking first image in batch\n",
    "        ground_truth_mask = sample[1]\n",
    "        \n",
    "        # Predict\n",
    "        pred_mask = model.predict(input_image, verbose=0)\n",
    "        \n",
    "        image = input_image.numpy()[0]\n",
    "        #print(input_image)\n",
    "        #image = (image - image.min()) / (image.max() - image.min())  # Normalize to [0, 1]\n",
    "        #print(image)\n",
    "        # Plot input, ground truth, and prediction\n",
    "        plt.subplot(num_samples, 3, i*3 + 1)\n",
    "        plt.imshow(image)\n",
    "        plt.title(\"Input Image\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(num_samples, 3, i*3 + 2)\n",
    "        plt.imshow(ground_truth_mask.numpy()[0], cmap='gray')\n",
    "        plt.title(\"Ground Truth Mask\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        pred_mask[0] = pred_mask[0]\n",
    "        plt.subplot(num_samples, 3, i*3 + 3)\n",
    "        plt.imshow(pred_mask[0]>0.6, cmap='gray')\n",
    "        plt.title(\"Predicted Mask\")\n",
    "        plt.axis(\"off\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"dataset/unet/finalresults/sample_predictions_dataAugmentedmore.png\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Find the model with the best f1_score\n",
    "results_df = pd.read_csv(\"dataset/unet/results/results_unet.csv\")\n",
    "maxIndex = results_df[\"f2_score\"].idxmax()\n",
    "filter_count = results_df[\"filters\"][maxIndex]\n",
    "lr = results_df[\"learning_rate\"][maxIndex]\n",
    "batch_size = results_df[\"batch_size\"][maxIndex]\n",
    "\n",
    "filename = f'./dataset/unet/weights/unet_filters_{filter_count}_batch_{batch_size}_lr_{lr}.keras'\n",
    "\n",
    "# Load best model weights\n",
    "model = unet(lr=lr, filtersFirstLayer=filter_count, input_size=(image_size, image_size, 3))\n",
    "model.load_weights(filename)\n",
    "\n",
    "print(f\"Plot sample from file: {filename}\")\n",
    "plot_sample_predictions(train_ds, model,10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "landslide-image",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
