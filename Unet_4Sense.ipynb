{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train U-Net on the Landslide4Sense Dataset\n",
    "\n",
    "*Authors: Abdelouahed Drissi*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend\n",
    "import h5py\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from losses import  weighted_bce\n",
    "\n",
    "from tensorflow.keras.layers import  Activation, Multiply\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Costum Functions for data augmentation\n",
    "\n",
    "Augmentation s not recomended for this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define number of augmented copies per original image\n",
    "AUGMENTATION_FACTOR = 2\n",
    "\n",
    "# Define augmentation functions\n",
    "def random_flip(image, mask):\n",
    "    \"\"\"Random horizontal and vertical flips\"\"\"\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        image = tf.image.flip_left_right(image)\n",
    "        mask = tf.image.flip_left_right(mask)\n",
    "    \n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        image = tf.image.flip_up_down(image)\n",
    "        mask = tf.image.flip_up_down(mask)\n",
    "    \n",
    "    return image, mask\n",
    "\n",
    "def random_rotate(image, mask):\n",
    "    \"\"\"Random rotation (0째, 90째, 180째, 270째)\"\"\"\n",
    "    k = tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32)\n",
    "    image = tf.image.rot90(image, k=k)\n",
    "    mask = tf.image.rot90(mask, k=k)\n",
    "    return image, mask\n",
    "\n",
    "def random_brightness(image, mask):\n",
    "    \"\"\"Random brightness adjustment\"\"\"\n",
    "    image = tf.image.random_brightness(image, max_delta=0.7)\n",
    "    return image, mask\n",
    "\n",
    "def random_contrast(image, mask):\n",
    "    \"\"\"Random contrast adjustment\"\"\"\n",
    "    image = tf.image.random_contrast(image, lower=0.3, upper=1.4)\n",
    "    return image, mask\n",
    "\n",
    "def augment_data(image, mask):\n",
    "    \"\"\"Apply all augmentations sequentially\"\"\"\n",
    "    image, mask = random_flip(image, mask)\n",
    "    image, mask = random_rotate(image, mask)\n",
    "    image, mask = random_brightness(image, mask)\n",
    "    image, mask = random_contrast(image, mask)\n",
    "    return image, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories for images and mass\n",
    "train_image_dir = \"./dataset/Landslide4Sense/TrainData/img\"\n",
    "train_mask_dir = \"./dataset/Landslide4Sense/TrainData/mask\"\n",
    "valid_image_dir = \"./dataset/Landslide4Sense/ValidData/img\"\n",
    "valid_mask_dir = \"./dataset/Landslide4Sense/ValidData/mask\"\n",
    "test_image_dir = \"./dataset/Landslide4Sense/TestData/img\"\n",
    "test_mask_dir = \"./dataset/Landslide4Sense/TestData/mask\"\n",
    "\n",
    "# Constants for normalization\n",
    "IMAGE_SIZE = 256\n",
    "CHANNELS   = 14 \n",
    "\n",
    "# Step 1: Load dataset and match images with masks\n",
    "def load_data(image_dir, mask_dir=None):\n",
    "    image_names = sorted(os.listdir(image_dir))\n",
    "    pairs = []\n",
    "    for img_name in image_names:\n",
    "        img_path = os.path.join(image_dir, img_name)\n",
    "        if mask_dir:\n",
    "            mask_name = img_name.replace(\"image\", \"mask\")\n",
    "            mask_path = os.path.join(mask_dir, mask_name)\n",
    "            pairs.append((img_path, mask_path))\n",
    "        else:\n",
    "            pairs.append((img_path,))\n",
    "    return pairs\n",
    " \n",
    "\n",
    "\n",
    "train_data = load_data(train_image_dir, train_mask_dir)\n",
    "valid_data = load_data(valid_image_dir, valid_mask_dir)\n",
    "test_data = load_data(test_image_dir, test_mask_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean an STD calculation\n",
    "Run this cell if you want to recalculate Mean and STD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Dataset Statistics (Mean/Std)\n",
    "def compute_dataset_statistics(image_dir):\n",
    "    \"\"\"\n",
    "    Compute mean and standard deviation for each band in the dataset.\n",
    "    \"\"\"\n",
    "    image_paths = sorted([os.path.join(image_dir, f) for f in os.listdir(image_dir)])\n",
    "    sum_ = np.zeros(CHANNELS)\n",
    "    sum_sq = np.zeros(CHANNELS)\n",
    "    count = 0\n",
    "\n",
    "    for img_path in image_paths:\n",
    "        with h5py.File(img_path, 'r') as hf:\n",
    "            image = hf['img'][:]  # Shape: (H, W, C)\n",
    "            image = image.astype(np.float32)\n",
    "            \n",
    "            # Resize to target size (if needed)\n",
    "            image = tf.image.resize(image, (IMAGE_SIZE, IMAGE_SIZE), method=\"bilinear\")\n",
    "            \n",
    "            sum_ += np.mean(image, axis=(0, 1))\n",
    "            sum_sq += np.mean(image**2, axis=(0, 1))\n",
    "            count += 1\n",
    "\n",
    "    mean = sum_ / count\n",
    "    std = np.sqrt((sum_sq / count) - (mean ** 2))\n",
    "    return mean, std\n",
    "\n",
    "# Compute mean/std for the training data\n",
    "mean, std = compute_dataset_statistics(train_image_dir)\n",
    "\n",
    "# Convert to tensors for TensorFlow operations\n",
    "mean = tf.constant(mean, dtype=tf.float32)\n",
    "std = tf.constant(std, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization and Image Resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing functions\n",
    "def normalize(input_image, input_mask=None):\n",
    "    \n",
    "    input_image = tf.cast(input_image, dtype=tf.float32)\n",
    "    input_image = tf.convert_to_tensor(input_image, dtype=tf.float32)\n",
    "    # Resize image to 256x256\n",
    "    input_image = tf.image.resize(input_image, [IMAGE_SIZE, IMAGE_SIZE], method=\"bilinear\")\n",
    "    #input_image = (input_image - mean[None, None, :]) / tf.maximum(std[ None, None, :], tf.keras.backend.epsilon())# Uncomment this line if you want to normalize to [-1 1]\n",
    "    min_val = np.min(input_image)\n",
    "    max_val = np.max(input_image)\n",
    "\n",
    "    input_image = (input_image  - min_val) / (max_val - min_val)  \n",
    "    \n",
    "    if input_mask is not None:\n",
    "        input_mask = tf.cast(input_mask, tf.float32)\n",
    "        # If mask is one-hot encoded, convert to label image:\n",
    "        if input_mask.shape[-1] != 1:\n",
    "            input_mask = tf.argmax(input_mask, axis=-1, output_type=tf.int32)\n",
    "            input_mask = tf.expand_dims(input_mask, axis=-1)\n",
    "        input_mask = tf.image.resize(input_mask, (IMAGE_SIZE, IMAGE_SIZE), method=\"nearest\")\n",
    "        return input_image, input_mask\n",
    "    return input_image\n",
    "\n",
    "def load_image_file(image_path, mask_path=None):\n",
    "    with h5py.File(image_path, 'r') as hf:\n",
    "        image = hf['img'][:]\n",
    "    if mask_path:\n",
    "        with h5py.File(mask_path, 'r') as hf:\n",
    "            mask = hf['mask'][:]\n",
    "            # Make sure mask has 3 dimensions\n",
    "            if len(mask.shape) == 2:\n",
    "                mask = tf.expand_dims(mask, axis=-1)\n",
    "\n",
    "        return normalize(image, mask)\n",
    "    return normalize(image)\n",
    "\n",
    "# Modified load_data function with augmentation\n",
    "def load_data_with_augmentation(image_path, mask_path=None):\n",
    "    with h5py.File(image_path, 'r') as hf:\n",
    "        image = hf['img'][:]\n",
    "    if mask_path:\n",
    "        with h5py.File(mask_path, 'r') as hf:\n",
    "            mask = hf['mask'][:]\n",
    "            # Make sure mask has 3 dimensions\n",
    "            if len(mask.shape) == 2:\n",
    "                mask = tf.expand_dims(mask, axis=-1)\n",
    "\n",
    "    # Generate augmented data list\n",
    "    augmented_data = []\n",
    "    for _ in range(AUGMENTATION_FACTOR):\n",
    "        aug_image, aug_mask = augment_data(image, mask)\n",
    "        augmented_data.append((aug_image, aug_mask))\n",
    "\n",
    "    # Normalize and return a list of all images/masks including the original\n",
    "    normalized_original = normalize(image, mask)\n",
    "    normalized_augmented = [normalize(aug_img, aug_msk) for aug_img, aug_msk in augmented_data]\n",
    "\n",
    "    return [normalized_original] + normalized_augmented\n",
    "\n",
    "\n",
    "# Step 3: Create the dataset\n",
    "def generator(data, augment=False):\n",
    "    for item in data:\n",
    "        if len(item) == 2:\n",
    "            image_path, mask_path = item\n",
    "            if augment:\n",
    "                # load_data_with_augmentation returns a list of tuples\n",
    "                augmented_samples = load_data_with_augmentation(image_path, mask_path)\n",
    "                for sample in augmented_samples:\n",
    "                    yield sample  # yield each (image, mask) tuple individually\n",
    "            else:\n",
    "                yield load_image_file(image_path, mask_path)\n",
    "        else:\n",
    "            image_path = item[0]\n",
    "            if augment:\n",
    "                augmented_samples = load_data_with_augmentation(image_path)\n",
    "                for sample in augmented_samples:\n",
    "                    yield sample\n",
    "            else:\n",
    "                yield load_image_file(image_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build input pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset settings\n",
    "batch_size = 16\n",
    "auto = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = tf.data.Dataset.from_generator(\n",
    "    lambda: generator(train_data),\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(256,256, 14), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(256, 256, 1), dtype=tf.float32),\n",
    "    )\n",
    ").cache().shuffle(batch_size * 10).batch(batch_size).repeat().prefetch(auto)\n",
    "\n",
    "valid_ds = tf.data.Dataset.from_generator(\n",
    "    lambda: generator(valid_data),\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(256, 256, 14), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(256, 256, 1), dtype=tf.float32),\n",
    "    )\n",
    ").batch(batch_size).repeat().prefetch(auto)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_generator(\n",
    "    lambda: generator(test_data),\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(256, 256, 14), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(256, 256, 1), dtype=tf.float32),\n",
    "    )\n",
    ").batch(batch_size).prefetch(auto)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Samples from trainning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a batch of training data\n",
    "for images, masks in train_ds.take(2):\n",
    "    print(\"Image shape:\", images.shape)  # (batch_size, 256, 256, 14)\n",
    "    print(\"Mask shape:\", masks.shape)    # (batch_size, 256, 256, 1)\n",
    "    \n",
    "    print(images[0][:, :, 2:5])\n",
    "    # Plot first sample\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(images[0][:, :, 2:5])  # Show RGB bands (assuming bands 1-3 are RGB)\n",
    "    plt.title(\"Image (RGB Bands)\")\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(masks[0])\n",
    "    plt.title(\"Mask\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Metrics Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(y_true, y_pred):\n",
    "    y_pred = tf.round(y_pred)\n",
    "    true_positives = tf.reduce_sum(tf.round(y_true * y_pred))\n",
    "    possible_positives = tf.reduce_sum(tf.round(y_true))\n",
    "    return true_positives / (tf.cast(possible_positives,tf.float32) + tf.keras.backend.epsilon())\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    y_pred = tf.round(y_pred)\n",
    "    true_positives = tf.reduce_sum(tf.round(y_true * y_pred))\n",
    "    predicted_positives = tf.reduce_sum(tf.round(y_pred))\n",
    "    return true_positives / (predicted_positives + tf.keras.backend.epsilon())\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    return 2 * ((p * r) / (p + r + tf.keras.backend.epsilon()))\n",
    "\n",
    "def f2_score(y_true, y_pred):\n",
    "    \"\"\"F2-score prioritizing recall over precision\"\"\"\n",
    "    \n",
    "    # Precision and recall with stability\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    \n",
    "    # F-beta calculation (beta=2)\n",
    "    beta_sq = 4\n",
    "    return (1 + beta_sq) * (p * r) / (beta_sq * p + r + tf.keras.backend.epsilon())\n",
    "\n",
    "def iou_score(y_true, y_pred): \n",
    "    y_pred = tf.round(y_pred)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    union = tf.reduce_sum(y_true + y_pred) - intersection\n",
    "    return intersection / (union + tf.keras.backend.epsilon())\n",
    "\n",
    "def miss_rate(y_true, y_pred):\n",
    "    \"\"\"Percentage of undetected landslides\"\"\"\n",
    "    y_pred = tf.round(y_pred)\n",
    "    false_negatives = tf.reduce_sum(y_true * (1 - y_pred))\n",
    "    possible_positives = tf.reduce_sum(y_true)\n",
    "    \n",
    "    return tf.where(\n",
    "        possible_positives > 0,\n",
    "        false_negatives / (possible_positives + tf.keras.backend.epsilon()),\n",
    "        0.0  # No landslides to miss\n",
    "    )\n",
    "\n",
    "\n",
    "# Stateful metrics must be instantiated once\n",
    "#auc_pr_metric = tf.keras.metrics.AUC(curve='PR', name='auc_pr')\n",
    "\n",
    "def false_positive_rate(y_true, y_pred):\n",
    "    \"\"\"FP rate with edge case handling\"\"\"\n",
    "    y_pred = tf.round(y_pred)\n",
    "    \n",
    "    false_positives = tf.reduce_sum((1 - y_true) * y_pred)\n",
    "    true_negatives = tf.reduce_sum((1 - y_true) * (1 - y_pred))\n",
    "    \n",
    "    return tf.where(\n",
    "        (false_positives + true_negatives) > 0,\n",
    "        false_positives / (false_positives + true_negatives + tf.keras.backend.epsilon()),\n",
    "        0.0  # No negative samples\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout, BatchNormalization\n",
    "\n",
    "# Image bands\n",
    "img_bands = 14 \n",
    "# Loss function\n",
    "loss=weighted_bce\n",
    "\n",
    "def unet(lr,filtersFirstLayer,input_size = (IMAGE_SIZE,IMAGE_SIZE,CHANNELS)):\n",
    "    inputs = Input(input_size, name=\"pixel_values\")\n",
    "    conv1 = Conv2D(filtersFirstLayer, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(inputs)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Conv2D(filtersFirstLayer, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    #pool1 = Dropout(Dropout_Rate)(pool1)\n",
    "\n",
    "    conv2 = Conv2D(filtersFirstLayer*2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(pool1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Conv2D(filtersFirstLayer*2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    #pool2 = Dropout(Dropout_Rate)(pool2)\n",
    "\n",
    "    conv3 = Conv2D(filtersFirstLayer*4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(pool2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Conv2D(filtersFirstLayer*4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    #pool3 = Dropout(Dropout_Rate)(pool3)\n",
    "\n",
    "    conv4 = Conv2D(filtersFirstLayer*8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(pool3)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Conv2D(filtersFirstLayer*8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "    #pool4 = Dropout(Dropout_Rate)(pool4)\n",
    "\n",
    "    conv5 = Conv2D(filtersFirstLayer*16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(pool4)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Conv2D(filtersFirstLayer*16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(conv5)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    \n",
    "    up6 = Conv2D(filtersFirstLayer*8, 2, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(UpSampling2D(size = (2,2))(conv5))\n",
    "    merge6 = concatenate([conv4,up6], axis = 3)\n",
    "    conv6 = Conv2D(filtersFirstLayer*8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(merge6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Conv2D(filtersFirstLayer*8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    \n",
    "    up7 = Conv2D(filtersFirstLayer*4, 2, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = Conv2D(filtersFirstLayer*4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(merge7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    conv7 = Conv2D(filtersFirstLayer*4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(conv7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    \n",
    "    up8 = Conv2D(filtersFirstLayer*2, 2, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(filtersFirstLayer*2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(merge8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "    conv8 = Conv2D(filtersFirstLayer*2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(conv8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "    \n",
    "    up9 = Conv2D(filtersFirstLayer, 2, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    conv9 = Conv2D(filtersFirstLayer, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(merge9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "    conv9 = Conv2D(filtersFirstLayer, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(conv9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(conv9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "    \n",
    "    model = Model(inputs=inputs,  outputs=conv10)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer = Adam(learning_rate = lr)\n",
    "        , loss = loss\n",
    "        , metrics=[\n",
    "                    recall,\n",
    "                    f2_score,\n",
    "                    miss_rate,\n",
    "                    false_positive_rate,\n",
    "                    tf.keras.metrics.Precision(name='precision')  # Monitor but don't optimize\n",
    "                ]\n",
    "    )\n",
    "    print(\"Model input shape:\", model.input_shape)  # Expected: (None, image_size, image_size, 3)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "# Training and evaluation loop parameters\n",
    "filters = [4,8,16,32]\n",
    "learning_rates = [10e-3, 5e-4, 10e-4, 5e-5, 10e-5]\n",
    "batch_sizes = [4,8,16,32]\n",
    "epochs = 100\n",
    "\n",
    "steps_per_epoch = len(train_data) // batch_size  # Number of batches per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filter_count in filters:\n",
    "    for lr in learning_rates:\n",
    "        for batch in batch_sizes:\n",
    "            # Clean up memory\n",
    "            model = None\n",
    "            tf.keras.backend.clear_session() \n",
    "            gc.collect() \n",
    "            print(f\"Filters: {filter_count}, Learning Rate: {lr}, Batch Size: {batch}\")\n",
    "            model = unet(lr=lr, filtersFirstLayer=filter_count, input_size=(256, 256, 14))\n",
    "            early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=40, restore_best_weights=True)\n",
    "\n",
    "            # Save best model during training\n",
    "            checkpoint_path = f'./dataset/unet4Sense/weights/unet_filters_{filter_count}_batch_{batch}_lr_{lr}.keras'\n",
    "            model_checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, monitor='val_loss', save_best_only=True)\n",
    "\n",
    "            # Train the model\n",
    "            history = model.fit(\n",
    "                train_ds,\n",
    "                validation_data=valid_ds,\n",
    "                epochs=epochs,\n",
    "                steps_per_epoch=steps_per_epoch,\n",
    "                validation_steps=len(valid_data) // batch_size,\n",
    "                callbacks=[early_stop, model_checkpoint],\n",
    "                verbose=1\n",
    "            )\n",
    "\n",
    "            # Final evaluation\n",
    "            results = model.evaluate(test_ds)\n",
    "            print(f\"Test Recall: {results[1]:.2%}, Miss Rate: {results[3]:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing and Metric Comparison Across Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "results_dict = {\n",
    "    \"model\": [], \"batch_size\": [], \"learning_rate\": [], \"filters\": [],\n",
    "    \"precision\": [], \"recall\": [], \"f1_score\": [], \"iou_score\": [],\n",
    "    \"f2_score\": [],\"miss_rate\": [],\"false_positive_rate\": [],\n",
    "\n",
    "}\n",
    "\n",
    "checkpoint_path = f'./dataset/unet4Sense/weights'\n",
    "for filename in os.listdir(checkpoint_path):\n",
    "    # Only load files with the proper model file extension\n",
    "    if filename.endswith(\".keras\") : \n",
    "        # Clean up memory\n",
    "        model = None\n",
    "        tf.keras.backend.clear_session() \n",
    "        gc.collect()\n",
    "             \n",
    "        # Define the model structure\n",
    "        filter_count = int(filename.split('_')[2])\n",
    "        lr = float(filename.split('_')[6].split('.keras')[0])\n",
    "        batch = int(filename.split('_')[4])\n",
    "        model = unet(lr=lr, filtersFirstLayer=filter_count, input_size=(256, 256, 14))\n",
    "        \n",
    "        # Load best model weights\n",
    "        model.load_weights(os.path.join(checkpoint_path, filename))\n",
    "        print(f\"Evaluating model with checkpoint: {filename}\")\n",
    "        \n",
    "        # Evaluate on test data\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        print(test_ds.batch)\n",
    "        for (img,mask) in test_ds:\n",
    "            #print(\"sample:\", test_ds.shape)\n",
    "\n",
    "            pred = model.predict(img, verbose=0)\n",
    "            #print(\"pred shape:\", pred.shape)\n",
    "\n",
    "            y_true.append(mask.numpy())\n",
    "            y_pred.append(pred)\n",
    "        \n",
    "        y_true = np.concatenate(y_true, axis=0)\n",
    "        y_pred = np.concatenate(y_pred, axis=0)\n",
    "        \n",
    "         # Ensure both y_true and y_pred have the same shape for metrics\n",
    "        if y_pred.shape[-1] == 1:\n",
    "            y_pred = np.squeeze(y_pred, axis=-1)  # Remove the last dimension if it's 1\n",
    "        if y_true.shape[-1] == 1:\n",
    "            y_true = np.squeeze(y_true, axis=-1)\n",
    "\n",
    "        # Compute and collect metrics\n",
    "        precision_val = precision(y_true, y_pred).numpy()\n",
    "        recall_val = recall(y_true, y_pred).numpy()\n",
    "        f1_val = f1_score(y_true, y_pred).numpy()\n",
    "        iou_val = iou_score(y_true, y_pred).numpy()\n",
    "        \n",
    "        f2_val = f2_score(y_true, y_pred).numpy()\n",
    "        miss_rate_val = miss_rate(y_true, y_pred).numpy()\n",
    "        fpr_val = false_positive_rate(y_true, y_pred).numpy()\n",
    "\n",
    "        results_dict[\"precision\"].append(precision_val)\n",
    "        results_dict[\"recall\"].append(recall_val)\n",
    "        results_dict[\"f1_score\"].append(f1_val)\n",
    "        results_dict[\"iou_score\"].append(iou_val)\n",
    "        results_dict[\"f2_score\"].append(f2_val)\n",
    "        results_dict[\"miss_rate\"].append(miss_rate_val)\n",
    "        results_dict[\"false_positive_rate\"].append(fpr_val)\n",
    "\n",
    "        results_dict[\"model\"].append(\"U-Net\")\n",
    "        results_dict[\"batch_size\"].append(batch)\n",
    "        results_dict[\"learning_rate\"].append(lr)\n",
    "        results_dict[\"filters\"].append(filter_count)\n",
    "\n",
    "for key, value in results_dict.items():\n",
    "    print(key, len(value))\n",
    "# Convert results_dict to DataFrame and save as CSV\n",
    "results_df = pd.DataFrame(results_dict)\n",
    "results_df.to_csv(\"dataset/unet4Sense/res/results_unet.csv\", index=False)\n",
    "\n",
    "print(\"Validation and metric calculation completed, results saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Predictions (Ground Truth vs. Predicted Masks for model with the best F2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample_predictions(test_ds, model, num_samples=3):\n",
    "    plt.figure(figsize=(15, num_samples * 5))\n",
    "    \n",
    "    for i, (input_image,ground_truth_mask) in enumerate(test_ds.take(num_samples)):\n",
    "        \n",
    "        # Predict\n",
    "        pred_mask = model.predict(input_image, verbose=0)\n",
    "        \n",
    "        image = input_image.numpy()[0]\n",
    "        #image = (image - image.min()) / (image.max() - image.min())  # Normalize to [0, 1]\n",
    "        image = image[:,:,1:4]\n",
    "        # Plot input, ground truth, and prediction\n",
    "        plt.subplot(num_samples, 3, i*3 + 1)\n",
    "        plt.imshow(image)\n",
    "        plt.title(\"Input Image\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(num_samples, 3, i*3 + 2)\n",
    "        plt.imshow(ground_truth_mask.numpy()[0], cmap='gray')\n",
    "        plt.title(\"Ground Truth Mask\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        #pred_mask[0] = pred_mask[0]>0.001\n",
    "        plt.subplot(num_samples, 3, i*3 + 3)\n",
    "        plt.imshow(pred_mask[0], cmap='gray')\n",
    "        plt.title(\"Predicted Mask\")\n",
    "        plt.axis(\"off\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"dataset/unet4Sense/res/sample_predictions.png\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Find the model with the best f1_score\n",
    "results_df = pd.read_csv(\"dataset/unet4Sense/res/results_unet.csv\")\n",
    "maxIndex = results_df[\"f2_score\"].idxmax()\n",
    "filter_count = results_df[\"filters\"][maxIndex]\n",
    "lr = results_df[\"learning_rate\"][maxIndex]\n",
    "batch_size = results_df[\"batch_size\"][maxIndex]\n",
    "\n",
    "filename = f'./dataset/unet4Sense/weights/unet_filters_{filter_count}_batch_{batch_size}_lr_{lr}.keras'\n",
    "\n",
    "# Load best model weights\n",
    "model = unet(lr=lr, filtersFirstLayer=filter_count, input_size=(256, 256, 14))\n",
    "model.load_weights(filename)\n",
    "\n",
    "print(f\"Plot sample from file: {filename}\")\n",
    "plot_sample_predictions(test_ds, model,10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "landslide-image",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
